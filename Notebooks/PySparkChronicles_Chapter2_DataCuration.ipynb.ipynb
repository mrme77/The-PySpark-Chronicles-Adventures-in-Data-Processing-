{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17123a3c-3a3d-43d7-8ab1-dbb6a43ed3bb",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a178f51-fdc1-43cf-b73a-88a98a9437c7",
   "metadata": {},
   "source": [
    "### Libraries import and data ingestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650b6bf6-e03d-46d2-bdcb-460088b14e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_libraries import * \n",
    "import project_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5afe9666-27fc-45be-89f8-f169ae3700f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/19 15:17:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/04/19 15:17:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/04/19 15:17:19 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.debug.catalog\", False) \\\n",
    "    .config(\"spark.logLevel\", \"ERROR\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb74612d-8c73-4814-84a9-5b677849c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/Users/pasqualesalomone/Desktop/crime_data.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19034aa-875c-4d6f-8bff-d3fae1414a06",
   "metadata": {},
   "source": [
    "### Using lower case snake notation to standardize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab897d2-f575-4591-8665-7f562ce0adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_snake_case_lambda = lambda s: re.sub(r'\\W+', ' ', s).lower().replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ab4e51-e7c8-4e28-b71b-8454b28aeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [column_snake_case_lambda(col_name) for col_name in df.columns]\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "df = df.toDF(*new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36026ce-e96d-4f51-87ab-d5b5ceb51d0a",
   "metadata": {},
   "source": [
    "### Converting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34964d4a-95e6-4bd3-b2f7-d5623d150bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/19 15:17:37 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "df = (df.withColumn(\"date_rptd\", \n",
    "                   to_date(concat_ws(\"-\", split(substring(col('date_rptd'),1,10), \"/\")[2], \n",
    "                              split(substring(col('date_rptd'),1,10), \"/\")[0], \n",
    "                              split(substring(col('date_rptd'),1,10), \"/\")[1]),'yyyy-mm-dd'))\\\n",
    "      .withColumn(\"date_occ\", \n",
    "                   to_date(concat_ws(\"-\", split(substring(col('date_occ'),1,10), \"/\")[2], \n",
    "                              split(substring(col('date_occ'),1,10), \"/\")[0], \n",
    "                              split(substring(col('date_occ'),1,10), \"/\")[1]),'yyyy-mm-dd'))\\\n",
    "\n",
    "      #.withColumn('time_occ',col('time_occ').cast('string'))\n",
    "      .withColumn('weapon_used_cd', col('weapon_used_cd').cast('string'))\n",
    "      .withColumn('premis_cd', col('premis_cd').cast('string'))\n",
    "      .withColumn('crm_cd', col('crm_cd').cast('string'))\n",
    "      .withColumn('area', col('area').cast('string'))\n",
    "      .withColumn('crm_cd_1', col('crm_cd_1').cast('string'))\n",
    "      .withColumn('crm_cd_2', col('crm_cd_2').cast('string'))\n",
    "      .withColumn('crm_cd_3', col('crm_cd_3').cast('string'))\n",
    "      .withColumn('crm_cd_4', col('crm_cd_4').cast('string'))\n",
    "      .withColumn('rpt_dist_no',col('rpt_dist_no').cast('string')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1fd10f-d611-4625-8bdc-d02c98fd0872",
   "metadata": {},
   "source": [
    "### Renaming dr_no column to crime_record_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14ff96d-ce3b-4858-ab45-1cc5339d5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('dr_no','crime_record_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710bd9ed-c450-408f-b890-ab8dcc2d1a6e",
   "metadata": {},
   "source": [
    "### Creating a new column days_to_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fdf52d5-fc88-4997-841b-b8c830e54470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/19 15:17:48 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " crime_record_id       | 190326475            \n",
      " date_rptd             | 2020-01-01           \n",
      " date_occ              | 2020-01-01           \n",
      " time_occ              | 2130                 \n",
      " area                  | 7                    \n",
      " area_name             | Wilshire             \n",
      " rpt_dist_no           | 784                  \n",
      " part_1_2              | 1                    \n",
      " crm_cd                | 510                  \n",
      " crm_cd_desc           | VEHICLE - STOLEN     \n",
      " mocodes               | NULL                 \n",
      " vict_age              | 0                    \n",
      " vict_sex              | M                    \n",
      " vict_descent          | O                    \n",
      " premis_cd             | 101                  \n",
      " premis_desc           | STREET               \n",
      " weapon_used_cd        | NULL                 \n",
      " weapon_desc           | NULL                 \n",
      " status                | AA                   \n",
      " status_desc           | Adult Arrest         \n",
      " crm_cd_1              | 510                  \n",
      " crm_cd_2              | 998                  \n",
      " crm_cd_3              | NULL                 \n",
      " crm_cd_4              | NULL                 \n",
      " location              | 1900 S  LONGWOOD ... \n",
      " cross_street          | NULL                 \n",
      " lat                   | 34.0375              \n",
      " lon                   | -118.3506            \n",
      " column_days_to_report | 0                    \n",
      "-RECORD 1-------------------------------------\n",
      " crime_record_id       | 200106753            \n",
      " date_rptd             | 2020-01-09           \n",
      " date_occ              | 2020-01-08           \n",
      " time_occ              | 1800                 \n",
      " area                  | 1                    \n",
      " area_name             | Central              \n",
      " rpt_dist_no           | 182                  \n",
      " part_1_2              | 1                    \n",
      " crm_cd                | 330                  \n",
      " crm_cd_desc           | BURGLARY FROM VEH... \n",
      " mocodes               | 1822 1402 0344       \n",
      " vict_age              | 47                   \n",
      " vict_sex              | M                    \n",
      " vict_descent          | O                    \n",
      " premis_cd             | 128                  \n",
      " premis_desc           | BUS STOP/LAYOVER ... \n",
      " weapon_used_cd        | NULL                 \n",
      " weapon_desc           | NULL                 \n",
      " status                | IC                   \n",
      " status_desc           | Invest Cont          \n",
      " crm_cd_1              | 330                  \n",
      " crm_cd_2              | 998                  \n",
      " crm_cd_3              | NULL                 \n",
      " crm_cd_4              | NULL                 \n",
      " location              | 1000 S  FLOWER   ... \n",
      " cross_street          | NULL                 \n",
      " lat                   | 34.0444              \n",
      " lon                   | -118.2628            \n",
      " column_days_to_report | 1                    \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('column_days_to_report', datediff(\n",
    "                                                col('date_rptd'),col('date_occ')))\n",
    "df.show(2,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72103ea8-3527-4c1e-9323-b7dda2316850",
   "metadata": {},
   "source": [
    "### Creating new columns crime_occ_hour,crime_occ_minutes, and drop the time_occ column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4dc752f-1a08-4b6c-97d6-ef48505f9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day, month, and year from date_occ and date_rptd\n",
    "df = df.withColumn(\"crime_day_occ\", dayofmonth(\"date_occ\")) \\\n",
    "       .withColumn(\"crime_month_occ\", month(\"date_occ\")) \\\n",
    "       .withColumn(\"crime_year_occ\", year(\"date_occ\")) \\\n",
    "       .withColumn(\"crime_day_rptd\", dayofmonth(\"date_rptd\")) \\\n",
    "       .withColumn(\"crime_month_rptd\", month(\"date_rptd\")) \\\n",
    "       .withColumn(\"crime_year_rptd\", year(\"date_rptd\")) \\\n",
    "       .withColumn(\"crime_occ_hour\", (df[\"time_occ\"] / 100).cast(\"int\"))\\\n",
    "       .withColumn(\"crime_occ_minute\", df[\"time_occ\"] % 100)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(\"time_occ\", \"date_rptd\", \"date_occ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a35ae5-444c-499d-a829-1ccf16f617ce",
   "metadata": {},
   "source": [
    "### Dropping columns with a nulls ratio grater than 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393bea22-1b0c-49e8-9f54-75b3514feb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>%null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crm_cd_4</td>\n",
       "      <td>99.993086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crm_cd_3</td>\n",
       "      <td>99.755866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crm_cd_2</td>\n",
       "      <td>92.736789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cross_street</td>\n",
       "      <td>84.312103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weapon_used_cd</td>\n",
       "      <td>65.464611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weapon_desc</td>\n",
       "      <td>65.464611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mocodes</td>\n",
       "      <td>13.985006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vict_descent</td>\n",
       "      <td>13.305103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vict_sex</td>\n",
       "      <td>13.304023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>premis_desc</td>\n",
       "      <td>0.060385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>premis_cd</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>crm_cd_1</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       column_name      %null\n",
       "0         crm_cd_4  99.993086\n",
       "1         crm_cd_3  99.755866\n",
       "2         crm_cd_2  92.736789\n",
       "3     cross_street  84.312103\n",
       "4   weapon_used_cd  65.464611\n",
       "5      weapon_desc  65.464611\n",
       "6          mocodes  13.985006\n",
       "7     vict_descent  13.305103\n",
       "8         vict_sex  13.304023\n",
       "9      premis_desc   0.060385\n",
       "10       premis_cd   0.001188\n",
       "11        crm_cd_1   0.001188"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_function.nulls_buster(df,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6545379-abb3-489e-96c5-afbe8b2dbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('weapon_desc','weapon_used_cd','cross_street','crm_cd_2','crm_cd_3','crm_cd_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4928b45-5ba1-4a97-983a-77712873ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupBy('vict_descent').count().orderBy('count', ascending=False).first()['vict_descent']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6687b21e-b679-45f6-a3ff-f60915a18078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df1 = df.toPandas().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e9b4e4-1a65-4f59-a5c4-71c46fe4939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null or whitespace values in 'vict_sex': 13.304022814673983\n"
     ]
    }
   ],
   "source": [
    "# # Calculate the total number of rows\n",
    "# total_rows = len(df1)\n",
    "\n",
    "# # Count the number of null or whitespace values in the 'vict_sex' column\n",
    "# null_or_whitespace_count = df1['vict_sex'].isnull().sum() + (df1['vict_sex'] == '').sum()\n",
    "\n",
    "# # Calculate the percentage\n",
    "# percentage_null_or_whitespace = (null_or_whitespace_count / total_rows) * 100\n",
    "\n",
    "# print(\"Percentage of null or whitespace values in 'vict_sex':\", percentage_null_or_whitespace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31eddbc0-929c-4746-8944-dcd039dd8ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null or whitespace values in 'vict_sex': 13.304022814673983\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import col\n",
    "\n",
    "# # Calculate the total number of rows\n",
    "# total_rows = df.count()\n",
    "\n",
    "# # Count the number of null or whitespace values in the 'vict_sex' column\n",
    "# null_or_whitespace_count = df.filter((col('vict_sex').isNull()) | (col('vict_sex') == '')).count()\n",
    "\n",
    "# # Calculate the percentage\n",
    "# percentage_null_or_whitespace = (null_or_whitespace_count / total_rows) * 100\n",
    "\n",
    "# print(\"Percentage of null or whitespace values in 'vict_sex':\", percentage_null_or_whitespace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4ca7525-83ce-4017-b90b-7603fc6fe41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vict_sex\n",
      "M    429384\n",
      "F    382973\n",
      "X     96815\n",
      "H       121\n",
      "-         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Method 1: Impute missing values with the mode\n",
    "# mode_value = df1['vict_sex'].mode()[0]\n",
    "# df_mode = df1.fillna({'vict_sex': mode_value})\n",
    "\n",
    "# # Method 2: Impute missing values with a probability-based approach\n",
    "# value_counts = df1['vict_sex'].value_counts(normalize=True,dropna=False)\n",
    "# missing_indices = df1[df1['vict_sex'].isna() | df1['vict_sex'].str.isspace()].index\n",
    "# imputed_values = np.random.choice(value_counts.index, size=len(missing_indices), p=value_counts.values)\n",
    "# df_prob = df1.copy()\n",
    "# df_prob.loc[missing_indices, 'vict_sex'] = imputed_values\n",
    "# print(df_prob['vict_sex'].value_counts())\n",
    "\n",
    "# # Compare the results\n",
    "# # print(\"Original DataFrame:\")\n",
    "# # print(df1['vict_sex'])\n",
    "# # print(\"\\nImputed DataFrame using mode:\")\n",
    "# # print(df_mode['vict_sex'])\n",
    "# # print(\"\\nImputed DataFrame using probability-based approach:\")\n",
    "# # print(df_prob['vict_sex'])\n",
    "# #(df_prob['vict_sex'] != df_mode['vict_sex']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77e55f98-efe1-47b1-8db1-00b666b98a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df1 = df.toPandas().copy()\n",
    "\n",
    "# # Calculate the probability distribution of existing values in the 'vict_sex' column\n",
    "# value_counts = df1['vict_sex'].value_counts(normalize=True)\n",
    "# df1['vict_sex'].replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "\n",
    "# # Get indices of rows with missing values\n",
    "# missing_indices = df1[df1['vict_sex'].isna()].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "542dba03-0662-4a00-893d-77a162dbfdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed_values = np.random.choice(value_counts.index, size=len(missing_indices), p=value_counts.values)\n",
    "# df1.loc[missing_indices, 'vict_sex'] = imputed_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf934b-8abd-4f22-a435-46fe6e7a303c",
   "metadata": {},
   "source": [
    "### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fea6fe49-891f-4b45-a947-75a5f4264b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = project_function.impute_missing_values(df, [\n",
    "        \"mocodes\",\n",
    "        \"vict_descent\",\n",
    "        \"vict_sex\",\n",
    "        \"premis_desc\",\n",
    "        \"premis_cd\",\n",
    "        \"crm_cd_1\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe4beb89-f639-4b71-a12e-add9efe2800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "# def jaccard_similarity(list1, list2):\n",
    "#     set1 = set(list1)\n",
    "#     set2 = set(list2)\n",
    "#     intersection = len(set1.intersection(set2))\n",
    "#     union = len(set1.union(set2))\n",
    "#     return intersection / union\n",
    "\n",
    "\n",
    "\n",
    "# similarity = jaccard_similarity(setone, settwo)\n",
    "# print(\"Jaccard similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef143747-17d5-4514-9e0a-462e092eae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df.select(sum(col('mocodes').isNull().cast('int'))).collect()[0][0]\n",
    "#df.filter((F.col('mocodes').isNull()) | (F.col('mocodes') == '')).count()\n",
    "#df.select(col('mocodes')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebbc66-f861-42a2-babb-460f2e57ca8a",
   "metadata": {},
   "source": [
    "### Ensuring that the nulls_buster function returns no more null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0565381c-6fa4-49e0-b22c-99ceb340eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>%null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [column_name, %null]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_function.nulls_buster(df,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e23793-d235-4024-8053-97064240a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupBy('mocodes').agg(F.count('*').alias('count')).orderBy('count',ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f0ac6-fcfb-4b41-a629-2641793c329f",
   "metadata": {},
   "source": [
    "### Dropping an uncategorized column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "832275f0-a70a-496f-8589-3e25a9ab57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('part_1_2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf5077-3a84-4767-8803-54d711613c17",
   "metadata": {},
   "source": [
    "### Data Integrity Check: Ensuring Validity of Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d7d171d-efa9-4c42-b4e1-efe3db925351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min_vict_age</th>\n",
       "      <td>-4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_lat</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_lon</th>\n",
       "      <td>-118.6676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_crime_day_occ</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_crime_month_occ</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_crime_year_occ</th>\n",
       "      <td>2020.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_crime_day_rptd</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_crime_month_rptd</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_crime_year_rptd</th>\n",
       "      <td>2020.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_vict_age</th>\n",
       "      <td>120.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_lat</th>\n",
       "      <td>34.3343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_lon</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_crime_day_occ</th>\n",
       "      <td>31.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_crime_month_occ</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_crime_year_occ</th>\n",
       "      <td>2024.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_crime_day_rptd</th>\n",
       "      <td>31.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_crime_month_rptd</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_crime_year_rptd</th>\n",
       "      <td>2024.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0\n",
       "min_vict_age            -4.0000\n",
       "min_lat                  0.0000\n",
       "min_lon               -118.6676\n",
       "min_crime_day_occ        1.0000\n",
       "min_crime_month_occ      1.0000\n",
       "min_crime_year_occ    2020.0000\n",
       "min_crime_day_rptd       1.0000\n",
       "min_crime_month_rptd     1.0000\n",
       "min_crime_year_rptd   2020.0000\n",
       "max_vict_age           120.0000\n",
       "max_lat                 34.3343\n",
       "max_lon                  0.0000\n",
       "max_crime_day_occ       31.0000\n",
       "max_crime_month_occ      1.0000\n",
       "max_crime_year_occ    2024.0000\n",
       "max_crime_day_rptd      31.0000\n",
       "max_crime_month_rptd     1.0000\n",
       "max_crime_year_rptd   2024.0000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_of_interest = ['vict_age', 'lat', 'lon', 'crime_day_occ', \n",
    "                       'crime_month_occ', 'crime_year_occ', \n",
    "                       'crime_day_rptd', 'crime_month_rptd', 'crime_year_rptd']\n",
    "\n",
    "min_max_df = df.select(*[min(col).alias(f\"min_{col}\") for col in columns_of_interest] +\n",
    "                      [max(col).alias(f\"max_{col}\") for col in columns_of_interest])\n",
    "\n",
    "min_max_df.toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec502c40-ab23-4c95-ada3-cad0f3a0bcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with negative values in the field vict_age is 112 or the 0.00012098690748822538 %\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows with negative values in any of the selected columns\n",
    "negative_values_df = df.filter(\n",
    "    (col(\"vict_age\") < 0) \n",
    ")\n",
    "\n",
    "print(f\"The number of rows with negative values in the field vict_age is {negative_values_df.toPandas().shape[0]} or the {negative_values_df.toPandas().shape[0]/df.count()} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954b08c-b4c4-4aa6-8b2c-3d6111c49a31",
   "metadata": {},
   "source": [
    "### Replacing neegative vict_age values with positive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23f1b379-c4b8-4038-9b57-6a26caafb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"vict_age\", when(col(\"vict_age\") < 0, -col(\"vict_age\")).otherwise(col(\"vict_age\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "388df32a-9a6a-4f1e-9ea3-3f8691cfcfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with negative values in the field vict_age after the transformation is 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of rows with negative values in the field vict_age after the transformation is {df.filter((col('vict_age') < 0)).count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b7bd3-ee85-438d-9af4-b2b099140f92",
   "metadata": {},
   "source": [
    "### Replace \"-\" with \"unknown\" in the vict_sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c23cc67b-f005-4ffe-b3e4-88b27d60248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"vict_sex\", when(col(\"vict_sex\") == \"-\", \"unknown\").otherwise(col(\"vict_sex\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2408394e-bc4e-47de-a8aa-7031a47cc9e8",
   "metadata": {},
   "source": [
    "#### Writing the curated df to a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62c9d666-8fa5-42bd-8d27-0f1ad1643169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"curated_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac65406-0f43-4fcf-bcc1-6067c206cf36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

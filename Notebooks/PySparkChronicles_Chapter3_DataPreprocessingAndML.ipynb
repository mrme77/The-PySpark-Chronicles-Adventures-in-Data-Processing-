{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0c1f73-35b0-43be-a834-c5bdf70ff871",
   "metadata": {},
   "source": [
    "### Libraries and data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2a282c-36ea-4462-be3b-d6d9abf946ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_libraries import * \n",
    "import project_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57124fb-1767-40c0-a71f-cef052b827cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/28 18:23:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.debug.catalog\", False) \\\n",
    "    .config(\"spark.logLevel\", \"ERROR\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faf5fa7-5c86-4849-ab6e-b9157e0758c5",
   "metadata": {},
   "source": [
    "### Data Preprocessing for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f54111-fe6c-4790-827c-1b7dd98ac5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "curated_df = spark.read.parquet(\"curated_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7513a-b84d-4fa9-be13-29c11563a4f5",
   "metadata": {},
   "source": [
    "#### Binary classification is a type of supervised machine learning problem where the goal is to predict categorical target variables that can take one of two possible classes. One example of binary classification specific to this project is include identifying whether a crime if of robbery type or not. In this context, models like logistic regression, decision trees, and support vector machines are typically employed to estimate the probability that a given input belongs to a particular class, usually denoted as 1 for the positive class and 0 for the negative class. The performance of binary classification models is often evaluated using metrics such as accuracy, precision, recall, F1 score, and ROC-AUC, which help to understand various aspects of the model's ability to correctly predict and distinguish between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b920734-2089-4d74-a477-0cbe072faa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df = curated_df.withColumn('robbery_crime_type', when(col('crm_cd_desc') == 'ROBBERY', 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef06258-6ffd-42aa-8bb4-6514afc8c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df = curated_df.drop('crm_cd_desc','crm_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb14f06e-e7f7-43d9-98a6-849920526f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curated_df.select(col('crm_cd_desc')).distinct().show(40,truncate=False)\n",
    "#curated_df.groupBy('crm_cd_desc').count().orderBy(col('count').desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d8630-2fc3-4e01-8789-6b2ea566c5d9",
   "metadata": {},
   "source": [
    "#### Assessing the balance of the class instances (one class is significantly more prevalent than the other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015d186b-744e-4df2-8f2c-288a38a18fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curated_df.toPandas().stalking_crime_type.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7207d606-e902-4bdb-9633-d3b20fa86c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+--------------------+\n",
      "|robbery_crime_type| count|          proportion|\n",
      "+------------------+------+--------------------+\n",
      "|                 1| 31521|0.034050252776217434|\n",
      "|                 0|894199|  0.9659497472237826|\n",
      "+------------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "robbery_type_counts = curated_df.groupBy('robbery_crime_type').count()\n",
    "\n",
    "# Calculate the proportion of each crime type\n",
    "proportions = robbery_type_counts.withColumn('proportion', F.col('count') / curated_df.count())\n",
    "\n",
    "proportions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79e75c-c3c6-431a-bf94-a75d4f5fab5d",
   "metadata": {},
   "source": [
    "#### Assessing categorical feature vict_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94da593c-a5dd-4ab6-9d41-82408f41447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|vict_sex|\n",
      "+--------+\n",
      "|       F|\n",
      "| unknown|\n",
      "|       M|\n",
      "|       X|\n",
      "|       H|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "curated_df.select('vict_sex').distinct().show()\n",
    "#count().orderBy('count', ascending=False).first()['vict_sex']\n",
    "#df.groupBy('vict_descent').count().orderBy('count', ascending=False).first()['vict_descent']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3f7be-7130-4f12-994d-996d932a5804",
   "metadata": {},
   "source": [
    "#### Convert categorical features with one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a288efda-a219-4c21-852f-02f74ac04521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# StringIndexer to convert the 'vict_sex' column into numerical indices\n",
    "stringIndexer = StringIndexer(inputCol=\"vict_sex\", outputCol=\"vict_sex_type_indexed\")\n",
    "\n",
    "# OneHotEncoder to encode the numerical indices into one-hot encoded vectors\n",
    "encoder = OneHotEncoder(inputCol=\"vict_sex_type_indexed\", outputCol=\"vict_sex_type_encoded\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['vict_age', 'crime_day_occ', 'crime_month_occ', 'crime_year_occ', \n",
    "                     \n",
    "                                       'crime_day_rptd', 'crime_month_rptd', 'crime_year_rptd', \n",
    "                                       'vict_sex_type_indexed'], outputCol='features')\n",
    "# Define a pipeline that includes both StringIndexer and OneHotEncoder\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder,assembler])\n",
    "\n",
    "# Fit the pipeline to the DataFrame and transform the DataFrame\n",
    "curated_df_encoded = pipeline.fit(curated_df).transform(curated_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc75face-5099-4572-a187-67d078893fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df_encoded = curated_df_encoded.drop('vict_sex')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8a4c3-431f-417f-ac91-11d84e139be2",
   "metadata": {},
   "source": [
    "#### Subsetting datasets with features of interest for later use into SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed1141c5-232e-4f9b-8567-2ca66a1fd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = curated_df_encoded.select('vict_age','crime_day_occ', \n",
    "                                 'crime_month_occ', 'crime_year_occ', 'crime_day_rptd', \n",
    "                                 'crime_month_rptd', 'crime_year_rptd', \n",
    "                                 'robbery_crime_type','vict_sex_type_indexed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19943502-3985-44aa-b849-e382babf78cb",
   "metadata": {},
   "source": [
    "#### Fitting a model without scaling the data and ignoring class unbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5b8bf8b-d67b-43cb-8b87-0b9a743a236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = curated_df_encoded.randomSplit([0.8, 0.2], seed=42)\n",
    "# Define the logistic regression model\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='robbery_crime_type')\n",
    "\n",
    "# Define a pipeline that includes StringIndexer, OneHotEncoder, VectorAssembler, and the logistic regression model\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "# Fit the pipeline to the DataFrame\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Transform the DataFrame using the pipeline\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82c2c37-26df-4cc3-b7e9-4056c52a022c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " crime_record_id       | 200100001            \n",
      " area                  | 1                    \n",
      " area_name             | Central              \n",
      " rpt_dist_no           | 111                  \n",
      " mocodes               | 0344                 \n",
      " vict_age              | 0                    \n",
      " vict_descent          | H                    \n",
      " premis_cd             | 108                  \n",
      " premis_desc           | PARKING LOT          \n",
      " status                | AA                   \n",
      " status_desc           | Adult Arrest         \n",
      " crm_cd_1              | 510                  \n",
      " location              | 500 N  FIGUEROA  ... \n",
      " lat                   | 34.0617              \n",
      " lon                   | -118.2469            \n",
      " column_days_to_report | 1                    \n",
      " crime_day_occ         | 25                   \n",
      " crime_month_occ       | 1                    \n",
      " crime_year_occ        | 2020                 \n",
      " crime_day_rptd        | 26                   \n",
      " crime_month_rptd      | 1                    \n",
      " crime_year_rptd       | 2020                 \n",
      " crime_occ_hour        | 20                   \n",
      " crime_occ_minute      | 0                    \n",
      " robbery_crime_type    | 0                    \n",
      " vict_sex_type_indexed | 0.0                  \n",
      " vict_sex_type_encoded | (4,[0],[1.0])        \n",
      " features              | [0.0,25.0,1.0,202... \n",
      " rawPrediction         | [3.27929233927046... \n",
      " probability           | [0.96371154371383... \n",
      " prediction            | 0.0                  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12f1bb2-62f1-4e33-8242-9154590de1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------+--------------------+\n",
      "|            features|robbery_crime_type|prediction|         probability|\n",
      "+--------------------+------------------+----------+--------------------+\n",
      "|[0.0,25.0,1.0,202...|                 0|       0.0|[0.96371154371383...|\n",
      "|[31.0,14.0,1.0,20...|                 0|       0.0|[0.96565364481987...|\n",
      "|[0.0,4.0,1.0,2020...|                 0|       0.0|[0.96815823170409...|\n",
      "|[34.0,19.0,1.0,20...|                 0|       0.0|[0.96173412740292...|\n",
      "|[0.0,24.0,1.0,202...|                 0|       0.0|[0.95796554058383...|\n",
      "|[49.0,19.0,1.0,20...|                 0|       0.0|[0.96443570711348...|\n",
      "|[39.0,11.0,1.0,20...|                 0|       0.0|[0.96620712679914...|\n",
      "|[0.0,11.0,1.0,202...|                 0|       0.0|[0.96130481830205...|\n",
      "|[23.0,2.0,1.0,202...|                 0|       0.0|[0.96841640623762...|\n",
      "|[24.0,3.0,1.0,202...|                 0|       0.0|[0.96807728051289...|\n",
      "+--------------------+------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC: 0.5358\n"
     ]
    }
   ],
   "source": [
    "# Show some predictions\n",
    "predictions.select(\"features\", 'robbery_crime_type', \"prediction\", \"probability\").show(10)\n",
    "\n",
    "# Evaluate the model using the BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"robbery_crime_type\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# Compute the area under the ROC curve\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(\"Area under ROC: {:.4f}\".format(auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fa71dac-eb42-4f21-a241-699d36ff4a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9329527042563608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9658947687281264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9491379895781019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluator object for classification metrics\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='robbery_crime_type', predictionCol='prediction')\n",
    "\n",
    "# Evaluate weighted precision\n",
    "evaluator.setMetricName(\"weightedPrecision\")\n",
    "precision = evaluator.evaluate(predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Evaluate weighted recall\n",
    "evaluator.setMetricName(\"weightedRecall\")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Evaluate F1 Score\n",
    "evaluator.setMetricName(\"f1\")\n",
    "f1Score = evaluator.evaluate(predictions)\n",
    "print(\"F1 Score:\", f1Score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48b7032a-d472-4c8c-93cc-a7cfe81dc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features = [curated_df.dtypes[value][0] for value in range(0,len(curated_df.columns)) if curated_df.dtypes[value][1]=='string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa970ce-b144-4499-80d8-187f0b321c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical_features = [curated_df.dtypes[value][0] for value in range(0,len(curated_df.columns)) if curated_df.dtypes[value][1]=='int' or curated_df.dtypes[value][1]=='double']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488de84-0eda-4ebc-b238-ce6f203ad6a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### The high precision, recall, and F1 score, contrast with the low Area Under the Curve (AUC) and can be indicative of several issues, particularly class imbalance. Given that the dataset is heavily skewed towards the negative class, it is likely that the model has developed a bias towards predicting negatives. This bias could result in high precision and recall, as the majority of predictions correctly identify the prevalent class, but it might lead to a low AUC. The AUC metric evaluates the model's ability to differentiate between classes across various thresholds, and a low AUC suggests that the model struggles to effectively rank the positive class highly when it is indeed the correct class. This scenario highlights a potential overfitting to the negative class while failing to generalize well across the less frequent positive instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb8028-c894-4304-83b4-8f76755dbcab",
   "metadata": {},
   "source": [
    "### Balance Class Distribution using SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67618e4-143c-4b78-ac90-bdcbb16033fd",
   "metadata": {},
   "source": [
    "#### Class imbalance occurs when one class in a classification problem significantly outweighs the other class. Itâ€™s common in many machine learning problems. SMOTE (Synthetic Minority Over-sampling Technique) is a technique used to balance class distributions by generating synthetic samples of the minority class. It works by creating new instances that are similar to existing minority class instances. This helps address imbalances in the dataset and improves the performance of machine learning models, especially those sensitive to class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6d5ec94-3ac6-4320-ab75-2c76a3d002f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "train_data_pd = data_model.toPandas()\n",
    "\n",
    "# Apply oversampling \n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(train_data_pd.drop('robbery_crime_type', axis=1), train_data_pd['robbery_crime_type'])\n",
    "\n",
    "# Combine resampled features and target variable\n",
    "resampled_df = pd.DataFrame(X_resampled, columns=train_data_pd.drop('robbery_crime_type', axis=1).columns)\n",
    "resampled_df['robbery_crime_type'] = y_resampled\n",
    "\n",
    "# Convert back to PySpark DataFrame\n",
    "train_data_balanced = spark.createDataFrame(resampled_df).repartition(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8f565-dd1c-420c-a26b-b5decb2f89fe",
   "metadata": {},
   "source": [
    "#### Check the new proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b5c58b6-018f-4060-b293-d7cad5cdb31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+----------+\n",
      "|robbery_crime_type| count|proportion|\n",
      "+------------------+------+----------+\n",
      "|                 0|894199|       0.5|\n",
      "|                 1|894199|       0.5|\n",
      "+------------------+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "robbery_type_counts = train_data_balanced.groupBy('robbery_crime_type').count()\n",
    "\n",
    "# Calculate the proportion of each crime type\n",
    "proportions = robbery_type_counts.withColumn('proportion', F.col('count') / resampled_df.shape[0])\n",
    "\n",
    "proportions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e3d4e-9746-4481-8bf6-847acf7e38f9",
   "metadata": {},
   "source": [
    "#### Creating a Vector Assembler which merges multiple columns into a single vector column. It's commonly used to assemble feature vectors for machine learning models in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0929dccf-e166-4067-b292-5c250ed19c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature vector assembler\n",
    "assembler = VectorAssembler(inputCols=['vict_age', 'crime_day_occ', 'crime_month_occ', 'crime_year_occ', \n",
    "                     \n",
    "                                       'crime_day_rptd', 'crime_month_rptd', 'crime_year_rptd', \n",
    "                                       'vict_sex_type_indexed'], outputCol='features')\n",
    "\n",
    "# Assemble features\n",
    "data_assembled = assembler.transform(train_data_balanced)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = data_assembled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a3264-c2f6-489a-9bca-44bc2dcb13b0",
   "metadata": {},
   "source": [
    "#### Now that the data preprocessing is complete, we fit the data into a logistic regression model to classify crimes as either robbery or non-robbery based on various features, evaluates its performance, and prints the accuracy of the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8962719-84d1-4d24-9605-0543f04b0d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.5526480480792335\n"
     ]
    }
   ],
   "source": [
    "# Define Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol='scaled_features', labelCol='robbery_crime_type')\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(stages=[scaler, lr])\n",
    "\n",
    "# Fit the pipeline\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='robbery_crime_type')\n",
    "auc_roc= evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f98ed3d-172f-41ab-8386-cf5781638a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5391892170113776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5427016961471699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 192:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5417315656572718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Initialize the evaluator object for classification metrics\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='robbery_crime_type', \n",
    "    predictionCol='prediction',\n",
    "    metricName='f1'  # Start with F1 Score\n",
    ")\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1Score = evaluator.evaluate(predictions)\n",
    "print(\"F1 Score:\", f1Score)\n",
    "\n",
    "# Calculate Precision\n",
    "evaluator.setMetricName(\"weightedPrecision\")\n",
    "precision = evaluator.evaluate(predictions)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate Recall\n",
    "evaluator.setMetricName(\"weightedRecall\")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d435db8-64b0-409a-b2a4-87c2d31dd94f",
   "metadata": {},
   "source": [
    "### Let's interpret each of these metrics:\n",
    "\n",
    "#### F1 Score: 0.5392\n",
    "- Definition: The F1 score is the harmonic mean of precision and recall. It is a measure of a test's accuracy that considers both the precision and the recall.\n",
    "- Interpretation: An F1 score of approximately 0.5392 is relatively low. This suggests that the balance between precision and recall is moderate, but overall, the effectiveness of the model in terms of both correctly identifying true positives and avoiding false positives is just above average.\n",
    "\n",
    "\n",
    "#### Precision: 0.5427\n",
    "- Definition: Precision is the ratio of correctly predicted positive observations to the total predicted positives. It answers the question, \"Of all the instances the model labeled as positive, how many were actually positive?\"\n",
    "- Interpretation: A precision of 0.5427 indicates that approximately 54.27% of the model's positive predictions were correct. This implies that the model is moderately effective at ensuring that its positive predictions are accurate, but there is a significant rate of false positives.\n",
    "\n",
    "#### Recall: 0.5417\n",
    "- Definition: Recall, or sensitivity, is the ratio of correctly predicted positive observations to all observations in the actual class. It measures the model's ability to find all the relevant cases (positive instances).\n",
    "- Interpretation: A recall of 0.5417 suggests that the model correctly identifies about 54.17% of all actual positives. This indicates a moderate ability to detect positive instances, missing nearly half of them.\n",
    "\n",
    "#### AUC ROC: 0.5526\n",
    "- Definition: The Area Under the Receiver Operating Characteristic Curve (AUC ROC) is a performance measurement for classification problems at various threshold settings. It tells how much the model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s.\n",
    "- Interpretation: An AUC ROC of 0.5526 is only slightly better than a random guess (0.5). This indicates that the model has a limited ability to discriminate between the positive and negative classes.\n",
    "### Overall Model Performance\n",
    "The metrics indicate that the model performs only slightly better than random guessing, particularly highlighted by the AUC ROC value. The moderate F1 score, precision, and recall further suggest that while the model has some predictive power, it's not highly effective or reliable for making decisions based on its current state.\n",
    "Possible alternative approaches include the following:\n",
    "\n",
    "- Random oversampling\n",
    "- Random undersampling\n",
    "- Oversampling with SMOTE\n",
    "- Oversampling with ADASYN\n",
    "- Undersampling with Tomek Link\n",
    "- Oversampling with SMOTE, then undersample with TOMEK Link (SMOTE-Tomek)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25dec19-9138-4f1e-ae92-fd102437ee87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
